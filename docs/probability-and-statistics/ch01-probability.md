 # 第一章 随机事件及其概率

## 1.1 随机事件

### 1.1.1 随机现象

在相同条件下重复进行试验或观察时，可能出现不同结果的现象称为**随机现象**。

**特点**：

1. **不确定性**：每次试验的结果不可预测。
2. **统计规律性**：大量重复试验后，结果会呈现出一定的规律性。

### 1.1.2 随机试验和随机事件

满足以下条件的试验称为**随机试验**，记作$E$：

1. 可以在相同条件下重复进行。
2. 每次试验的可能结果不止一个。
3. 试验前无法确定具体会出现哪个结果。

随机试验的某种可能结果或某些可能结果的集合称为**随机事件**，简称**事件**。

**分类**：

1. **基本事件**：试验中最简单的、不可再分的结果。
2. **复合事件**：由多个基本事件组成的事件。
3. **必然事件**：每次试验中必定发生的事件。
4. **不可能事件**：每次试验中必定不发生的事件。

### 1.1.3 样本空间

随机试验的所有可能结果组成的集合称为**样本空间**，记作$S$或$\varOmega$。

**特点**：

1. 样本空间中的每个元素称为**样本点**，即基本事件，记作$\omega$。
2. 样本空间可以是有限的、可数无限的或不可数无限的。

**例子**：

1. 抛硬币的样本空间：$S = \{\text{正面}, \text{反面}\}$。
2. 掷骰子的样本空间：$S = \{1, 2, 3, 4, 5, 6\}$。

### 1.1.4 事件之间的关系和运算

**事件的关系**：

1. **包含关系**：

   事件$A$发生必然导致事件$B$发生，记作$A \subset B$。

2. **相等关系**：

   事件$A$和$B$同时发生或不发生，记作$A = B$。

3. **互斥关系**：

   事件$A$和$B$不能同时发生，记作$AB = \varnothing$。

4. **对立关系**：

   若$AB=\varnothing$且$A\cup B=\varOmega$，则称事件$A$与$B$相互对立，在一次试验中至少有一个发生也至多有一个发生。

   事件$A$不发生的事件称为$A$的**对立事件**，记作$\overline{A}$。

**事件的运算**：

1. **并事件**：

   事件$A$或事件$B$发生，记作$A \cup B$。

   类似地，称 $\begin{align*}\bigcup^n_{i=1} A_i\end{align*}$ 为事件$A_1,A_2,\cdots,A_n$的和，称 $\begin{align*}\bigcup^\infty_{i=1} A_i\end{align*}$ 为事件$A_1,A_2,\cdots,A_\infty$的和。

2. **交事件**：

   事件$A$和事件$B$同时发生，记作$A \cap B$。

   类似地，称 $\begin{align*}\bigcap^n_{i=1} A_i\end{align*}$ 为事件$A_1,A_2,\cdots,A_n$的交，称 $\begin{align*}\bigcap^\infty_{i=1} A_i\end{align*}$ 为事件$A_1,A_2,\cdots,A_\infty$的交。

3. **差事件**：

   事件$A$发生而事件$B$不发生，记作$A - B$。

4. **补事件**：

   事件$A$不发生的事件，记作$\overline{A}$。

**运算律**：

1. **交换律**：
   $$
   \begin{align*}
   A \cup B = B \cup A\\
   A \cap B = B \cap A
   \end{align*}
   $$
   
2. **结合律**：
   $$
   \begin{align*}
   (A \cup B) \cup C = A \cup (B \cup C)\\
   (A \cap B) \cap C = A \cap (B \cap C)
   \end{align*}
   $$
   
3. **分配律**：
   $$
   \begin{align*}
   A \cup (B \cap C) = (A \cup B) \cap (A \cup C)\\
   A \cap (B \cup C) = (A \cap B) \cup (A \cap C)\\
   \bigcup_{i \in I} \left( A \cap B_i \right) = A \cap \left( \bigcup_{i \in I} B_i \right)\\
   \bigcap_{i \in I} \left( A \cup B_i \right) = A \cup \left( \bigcap_{i \in I} B_i \right)
   \end{align*}
   $$
   
4. **德摩根律**：
   $$
   \begin{align*}
   \overline{A \cup B} = \overline{A} \cap \overline{B}\\
   \overline{A \cap B} = \overline{A} \cup \overline{B}\\
   \overline{\bigcup_{i \in I} A_i} = \bigcap_{i \in I} \overline{A_i}\\
   \overline{\bigcap_{i \in I} A_i} = \bigcup_{i \in I} \overline{A_i}
   \end{align*}
   $$

## 1.2 随机事件的概率

### 1.2.1 事件的频率

在$n$次重复试验中，事件$A$发生的次数$n_A$称为事件$A$的**频数**，比值$\dfrac{n_A}{n}$称为事件$A$的**频率**，记作$f_n(A)$。

$$
f_n(A) = \frac{n_A}{n}
$$

**性质**：

1. **非负性**：$f_n(A) \geq 0$。
2. **归一性**：$f_n(S) = 1$，其中$S$为样本空间。
3. **可加性**：若事件$A$和$B$互斥，则$f_n(A \cup B) = f_n(A) + f_n(B)$。

当试验次数$n$充分大时，事件$A$的频率$f_n(A)$会在某个固定值附近波动，这一性质称为**频率的稳定性**。

### 1.2.2 概率的公理化定义

设$S$为样本空间，$\mathcal{F}$为$S$的某些子集组成的集合（称为事件域），若函数$P: \mathcal{F} \to [0, 1]$满足以下三条公理，则称$P$为**概率测度**，$P(A)$称为事件$A$的**概率**。

**公理**：

1. **非负性**：对于任意事件$A \in \mathcal{F}$，有$P(A) \geq 0$。

2. **归一性**：$P(S) = 1$。

3. **可列可加性**：对于任意可数个互不相容的事件$A_1, A_2, \dots$，有：
   $$
   P\left(\bigcup_{i=1}^{\infty} A_i\right) = \sum_{i=1}^{\infty} P(A_i)
   $$

**概率的性质**：

1. **不可能事件的概率**：$P(\varnothing) = 0$。

2. **有限可加性**：若事件$A_1, A_2, \dots, A_n$互不相容，则：
   $$
   P\left(\bigcup_{i=1}^{n} A_i\right) = \sum_{i=1}^{n} P(A_i)
   $$

3. **对立事件的概率**：$P(\overline{A}) = 1 - P(A)$。

4. **单调性**：若$A \subseteq B$，则$P(A) \leq P(B)$。

5. **加法公式**：对于任意两个事件$A$和$B$，有：
   $$
   P(A \cup B) = P(A) + P(B) - P(A \cap B)
   $$

## 1.3 古典概率模型

若随机试验满足以下两个条件，则称为**古典概率模型**：

1. **有限性**：样本空间$S$中的样本点总数有限。
2. **等可能性**：每个样本点出现的可能性相等。

在古典概率模型中，事件$A$的概率定义为：
$$
P(A) = \frac{\text{事件}A\text{包含的样本点数}}{\text{样本空间}S\text{中的样本点总数}} = \frac{|A|}{|S|}
$$

**古典概型局限性**：

1. **样本空间有限**：古典概率模型仅适用于样本空间有限的情况，无法处理无限样本空间的问题。
2. **等可能性假设**：古典概率模型要求每个样本点出现的可能性相等，但在实际问题中，这一条件可能不满足。

## 1.4 条件概率

### 1.4.1 条件概率的定义

在概率论中，**条件概率**描述的是在某一事件已经发生的条件下，另一事件发生的概率。设$A$和$B$是两个事件，且$P(B) > 0$，则事件$A$在事件$B$发生的条件下的条件概率定义为：

$$
P(A|B) = \frac{P(A  B)}{P(B)}
$$

条件概率也是概率，具有概率所有的性质：

1. **非负性**：$P(A|B) \geq 0$。

2. **归一性**：$P(\varOmega|B) = 1$。

3. **有限可加性**：对于任意可数个互不相容的事件$A_1, A_2, \dots$，有：
   $$
   P\left(\bigcup^\infty_{i=1}A_i|B\right)=\sum^\infty_{i=1}P(A_i|B)
   $$

4. **对立事件的概率**：$P(\overline{A}|B) = 1 - P(A|B)$。

5. **单调性**：若$A_1 \subset A_2$，则$P(A_1|B) \leq P(A_2|B)$。

6. **加法公式**：$P(A_1\cup A_2|B)=P(A_1|B)+P(A_2|B)-P(A_1A_2|B)$

### 1.4.2 概率的乘法公式

概率的乘法公式用于计算两个事件同时发生的概率，基于条件概率的定义。

1. **基本形式**：
   对于任意两个事件$A$和$B$，有：
   $$
   P(A \cap B) = P(A|B) \cdot P(B)
   $$
   或
   $$
   P(A \cap B) = P(B|A) \cdot P(A)
   $$

2. **推广形式**：
   对于$n$个事件$A_1, A_2, \dots, A_n$，有：
   $$
   P(A_1 \cap A_2 \cap \dots \cap A_n) = P(A_1) \cdot P(A_2|A_1) \cdot P(A_3|A_1 \cap A_2) \cdots P(A_n|A_1 \cap A_2 \cap \dots \cap A_{n-1})
   $$

乘法公式通过条件概率将多个事件同时发生的概率分解为单个事件的概率及其条件概率的乘积。

### 1.4.3 全概率公式与贝叶斯公式

#### 1.4.3.1 样本空间划分

设 $(\varOmega, \mathcal{F}, P)$ 是一个概率空间，其中$\varOmega$ 是**样本空间**，若一组事件 $\{A_i\}_{i \in I}$ 满足：
1. $A_i \cap A_j = \varnothing \quad (\forall i \neq j)$

2. $\begin{align*}\bigcup_{i=1}^n A_i = \varOmega\end{align*}$

则称 $\{A_i\}$ 为 $\Omega$ 的一个**划分**（partition）。

其中 $I$ 是有限或可数无穷指标集，划分为有穷划分（完备事件组）或可列无穷划分。

**性质：**

1. **互斥性**：$A_i$ 之间两两不交（$P(A_i \cap A_j) = 0$ 当 $i \neq j$）

2. **完备性**：所有 $A_i$ 的并覆盖样本空间（$P\left(\bigcup_i A_i\right) = 1$）

#### 1.4.3.2 全概率公式

**全概率公式**是概率论中用于计算一个事件的总概率的重要工具，特别是当该事件的发生依赖于多个互斥且完备的事件时。

设$B_1, B_2, \dots, B_n$是一组样本空间的划分，则对于任意事件$A$，其概率可以表示为：

$$
P(A) = \sum_{i=1}^n P(A|B_i) \cdot P(B_i)
$$

#### 1.4.3.3 贝叶斯公式

**贝叶斯公式**是概率论中用于更新事件概率的重要工具，特别是在已知某些条件下，重新评估事件发生的概率。它是条件概率和全概率公式的结合。

设$B_1, B_2, \dots, B_n$是一组样本空间的划分，对于任意事件$A$，且$P(A) > 0$，贝叶斯公式定义为：

$$
P(B_i|A) = \frac{P(A|B_i) \cdot P(B_i)}{P(A)}
$$

其中：

- $P(B_i|A)$ 是在事件$A$发生的条件下，事件$B_i$发生的**后验概率**。
- $P(A|B_i)$ 是在事件$B_i$发生的条件下，事件$A$发生的**条件概率**。
- $P(B_i)$ 是事件$B_i$发生的**先验概率**。
- $P(A)$ 是事件$A$发生的总概率，可以通过**全概率公式**计算：

$$
P(A) = \sum_{i=1}^n P(A|B_i) \cdot P(B_i)
$$

贝叶斯公式的核心思想是利用已知的信息（$A$发生）来更新我们对事件$B_i$发生概率的估计。它从先验概率$P(B_i)$出发，结合条件概率$P(A|B_i)$，得到后验概率$P(B_i|A)$。

## 1.5 随机事件的独立性

### 1.5.1 两个事件的独立性

设$A$和$B$是两个事件，若满足以下条件之一，则称$A$和$B$**相互独立**：

1. $P(A \cap B) = P(A) \cdot P(B)$。
2. $P(A|B) = P(A)$（当$P(B) > 0$时）。
3. $P(B|A) = P(B)$（当$P(A) > 0$时）。

事件$A$和$B$的独立性意味着事件$A$的发生与否不影响事件$B$的发生概率，反之亦然。

**性质**：

1. 若$A$和$B$独立，则$A$和$\overline{B}$、$\overline{A}$和$B$、$\overline{A}$和$\overline{B}$也独立。这四个命题间两两互为充要条件。
2. 独立性与互斥性不同：互斥事件$A$和$B$满足$P(A \cap B) = 0$，而独立事件$A$和$B$满足$P(A \cap B) = P(A) \cdot P(B)$，两者不能同时成立。

### 1.5.2 多个事件的独立性

设$A_1, A_2, \dots, A_n$是$n$个事件，若对于任意$k$（$2 \leq k \leq n$）和任意$1 \leq i_1 < i_2 < \dots < i_k \leq n$，都有：
$$
P(A_{i_1} \cap A_{i_2} \cap \dots \cap A_{i_k}) = P(A_{i_1}) \cdot P(A_{i_2}) \cdots P(A_{i_k})
$$
则称$A_1, A_2, \dots, A_n$**相互独立**。

多个事件的独立性意味着任意子集的事件同时发生的概率等于各事件概率的乘积。

**性质**：

1. 若$A_1, A_2, \dots, A_n$相互独立，则其中任意部分事件也相互独立。
2. 若$A_1, A_2, \dots, A_n$相互独立，则对任意事件$A_i$取补集后，事件组仍然相互独立。

