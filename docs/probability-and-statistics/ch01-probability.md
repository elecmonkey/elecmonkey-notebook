# 第一章 随机事件及其概率

## 1.1 随机事件

### 1.1.1 随机现象

在相同条件下重复进行试验或观察时，可能出现不同结果的现象称为**随机现象**。

**特点**：

1. **不确定性**：每次试验的结果不可预测。
2. **统计规律性**：大量重复试验后，结果会呈现出一定的规律性。

### 1.1.2 随机试验和随机事件

满足以下条件的试验称为**随机试验**，记作$E$：

1. 可以在相同条件下重复进行。
2. 每次试验的可能结果不止一个。
3. 试验前无法确定具体会出现哪个结果。

随机试验的某种可能结果或某些可能结果的集合称为**随机事件**，简称**事件**。

**分类**：

1. **基本事件**：试验中最简单的、不可再分的结果。
2. **复合事件**：由多个基本事件组成的事件。
3. **必然事件**：每次试验中必定发生的事件。
4. **不可能事件**：每次试验中必定不发生的事件。

### 1.1.3 样本空间

随机试验的所有可能结果组成的集合称为**样本空间**，记作$S$或$\varOmega$。

**特点**：

1. 样本空间中的每个元素称为**样本点**，即基本事件，记作$\omega$。
2. 样本空间可以是有限的、可数无限的或不可数无限的。

**例子**：

1. 抛硬币的样本空间：$S = \{\text{正面}, \text{反面}\}$。
2. 掷骰子的样本空间：$S = \{1, 2, 3, 4, 5, 6\}$。

### 1.1.4 事件之间的关系和运算

**事件的关系**：

1. **包含关系**：

   事件$A$发生必然导致事件$B$发生，记作$A \subset B$。

2. **相等关系**：

   事件$A$和$B$同时发生或不发生，记作$A = B$。

3. **互斥关系**：

   事件$A$和$B$不能同时发生，记作$AB = \varnothing$。

4. **对立关系**：

   若$AB=\varnothing$且$A\cup B=\varOmega$，则称事件$A$与$B$相互对立，在一次试验中至少有一个发生也至多有一个发生。

   事件$A$不发生的事件称为$A$的**对立事件**，记作$\overline{A}$。

**事件的运算**：

1. **并事件**：

   事件$A$或事件$B$发生，记作$A \cup B$。

   类似地，称 $\begin{align*}\bigcup^n_{i=1} A_i\end{align*}$ 为事件$A_1,A_2,\cdots,A_n$的和，称 $\begin{align*}\bigcup^\infty_{i=1} A_i\end{align*}$ 为事件$A_1,A_2,\cdots,A_\infty$的和。

2. **交事件**：

   事件$A$和事件$B$同时发生，记作$A \cap B$。

   类似地，称 $\begin{align*}\bigcap^n_{i=1} A_i\end{align*}$ 为事件$A_1,A_2,\cdots,A_n$的交，称 $\begin{align*}\bigcap^\infty_{i=1} A_i\end{align*}$ 为事件$A_1,A_2,\cdots,A_\infty$的交。

3. **差事件**：

   事件$A$发生而事件$B$不发生，记作$A - B$。
   
   **差事件的性质**：
   
   (1) $A - B = A \cap \overline{B}$：差事件可以表示为事件$A$与事件$B$的对立事件的交。
      这是因为"$A$发生且$B$不发生"等价于"$A$发生且$\overline{B}$发生"。
   
   (2) $(A - B) \cup B = A \cup B$：差事件与事件$B$的并等于事件$A$与事件$B$的并。
      推导：$(A - B) \cup B = (A \cap \overline{B}) \cup B = (A \cup B) \cap (\overline{B} \cup B) = (A \cup B) \cap \Omega = A \cup B$
   
   (3) $(A \cup B) - B = A - B$：事件$A$与事件$B$的并与事件$B$的差等于事件$A$与事件$B$的差。
      推导：$(A \cup B) - B = (A \cup B) \cap \overline{B} = (A \cap \overline{B}) \cup (B \cap \overline{B}) = (A \cap \overline{B}) \cup \varnothing = A \cap \overline{B} = A - B$

4. **补事件**：

   事件$A$不发生的事件，记作$\overline{A}$。

**运算律**：

1. **交换律**：
   $$
   \begin{align*}
   A \cup B = B \cup A\\
   A \cap B = B \cap A
   \end{align*}
   $$
   
2. **结合律**：
   $$
   \begin{align*}
   (A \cup B) \cup C = A \cup (B \cup C)\\
   (A \cap B) \cap C = A \cap (B \cap C)
   \end{align*}
   $$
   
3. **分配律**：
   $$
   \begin{align*}
   A \cup (B \cap C) = (A \cup B) \cap (A \cup C)\\
   A \cap (B \cup C) = (A \cap B) \cup (A \cap C)\\
   \bigcup_{i \in I} \left( A \cap B_i \right) = A \cap \left( \bigcup_{i \in I} B_i \right)\\
   \bigcap_{i \in I} \left( A \cup B_i \right) = A \cup \left( \bigcap_{i \in I} B_i \right)
   \end{align*}
   $$
   
4. **德摩根律**：
   $$
   \begin{align*}
   \overline{A \cup B} = \overline{A} \cap \overline{B}\\
   \overline{A \cap B} = \overline{A} \cup \overline{B}\\
   \overline{\bigcup_{i \in I} A_i} = \bigcap_{i \in I} \overline{A_i}\\
   \overline{\bigcap_{i \in I} A_i} = \bigcup_{i \in I} \overline{A_i}
   \end{align*}
   $$

## 1.2 随机事件的概率

### 1.2.1 事件的频率

在$n$次重复试验中，事件$A$发生的次数$n_A$称为事件$A$的**频数**，比值$\dfrac{n_A}{n}$称为事件$A$的**频率**，记作$f_n(A)$。

$$
f_n(A) = \frac{n_A}{n}
$$

**性质**：

1. **非负性**：$f_n(A) \geq 0$。
2. **归一性**：$f_n(S) = 1$，其中$S$为样本空间。
3. **可加性**：若事件$A$和$B$互斥，则$f_n(A \cup B) = f_n(A) + f_n(B)$。

当试验次数$n$充分大时，事件$A$的频率$f_n(A)$会在某个固定值附近波动，这一性质称为**频率的稳定性**。

### 1.2.2 概率的公理化定义

设$S$为样本空间，$\mathcal{F}$为$S$的某些子集组成的集合（称为事件域），若函数$P: \mathcal{F} \to [0, 1]$满足以下三条公理，则称$P$为**概率测度**，$P(A)$称为事件$A$的**概率**。

**公理**：

1. **非负性**：对于任意事件$A \in \mathcal{F}$，有$P(A) \geq 0$。

2. **归一性**：$P(S) = 1$。

3. **可列可加性**：对于任意可数个互不相容的事件$A_1, A_2, \dots$，有：
   $$
   P\left(\bigcup_{i=1}^{\infty} A_i\right) = \sum_{i=1}^{\infty} P(A_i)
   $$

**概率的性质**：

1. **不可能事件的概率**：$P(\varnothing) = 0$。

2. **有限可加性**：若事件$A_1, A_2, \dots, A_n$互不相容，则：
   $$
   P\left(\bigcup_{i=1}^{n} A_i\right) = \sum_{i=1}^{n} P(A_i)
   $$

3. **对立事件的概率**：$P(\overline{A}) = 1 - P(A)$。

4. **单调性**：若$A \subseteq B$，则$P(A) \leq P(B)$。

5. **加法与减法公式**：
   
   (1) **加法公式**：对于任意两个事件$A$和$B$，有：
   $$
   P(A \cup B) = P(A) + P(B) - P(A \cap B)
   $$
   
   对于任意三个事件$A$、$B$和$C$，加法公式可以推广为：
   $$
   P(A \cup B \cup C) = P(A) + P(B) + P(C) - P(A \cap B) - P(A \cap C) - P(B \cap C) + P(A \cap B \cap C)
   $$
   这一公式可以通过集合的包含-排除原理推导得出。更一般地，对于$n$个事件，可以用包含-排除原理计算其并集的概率。
   
   (2) **减法公式**：对于任意两个事件$A$和$B$，有：
   $$
   P(A - B) = P(A) - P(A \cap B)
   $$
   特别地，若$B \subset A$，则：
   $$
   P(A - B) = P(A) - P(B)
   $$
   推导：因为$A - B = A \cap \overline{B}$，且$A = (A \cap B) \cup (A \cap \overline{B})$，其中$(A \cap B)$与$(A \cap \overline{B})$互斥，所以$P(A) = P(A \cap B) + P(A \cap \overline{B})$，即$P(A - B) = P(A) - P(A \cap B)$。

6. **完备事件组的概率和**：若$\{A_i\}_{i=1}^{n}$是样本空间$\Omega$的一个完备事件组，则：
   $$
   \sum_{i=1}^{n} P(A_i) = 1
   $$
   这是因为完备事件组满足两两互斥且并集为样本空间的条件，由归一性和可列可加性公理可直接得出。

## 1.3 古典概率模型

若随机试验满足以下两个条件，则称为**古典概率模型**：

1. **有限性**：样本空间$S$中的样本点总数有限。
2. **等可能性**：每个样本点出现的可能性相等。

在古典概率模型中，事件$A$的概率定义为：
$$
P(A) = \frac{\text{事件}A\text{包含的样本点数}}{\text{样本空间}S\text{中的样本点总数}} = \frac{|A|}{|S|}
$$

**古典概型局限性**：

1. **样本空间有限**：古典概率模型仅适用于样本空间有限的情况，无法处理无限样本空间的问题。
2. **等可能性假设**：古典概率模型要求每个样本点出现的可能性相等，但在实际问题中，这一条件可能不满足。

## 1.4 条件概率

### 1.4.1 条件概率的定义

在概率论中，**条件概率**描述的是在某一事件已经发生的条件下，另一事件发生的概率。设$A$和$B$是两个事件，且$P(B) > 0$，则事件$A$在事件$B$发生的条件下的条件概率定义为：

$$
P(A|B) = \frac{P(A  B)}{P(B)}
$$

条件概率也是概率，具有概率所有的性质：

1. **非负性**：$P(A|B) \geq 0$。

2. **归一性**：$P(\varOmega|B) = 1$。

3. **有限可加性**：对于任意可数个互不相容的事件$A_1, A_2, \dots$，有：
   $$
   P\left(\bigcup^\infty_{i=1}A_i|B\right)=\sum^\infty_{i=1}P(A_i|B)
   $$

4. **对立事件的概率**：$P(\overline{A}|B) = 1 - P(A|B)$。

5. **单调性**：若$A_1 \subset A_2$，则$P(A_1|B) \leq P(A_2|B)$。

6. **加法公式**：$P(A_1\cup A_2|B)=P(A_1|B)+P(A_2|B)-P(A_1A_2|B)$

### 1.4.2 概率的乘法公式

概率的乘法公式用于计算两个事件同时发生的概率，基于条件概率的定义。

1. **基本形式**：
   对于任意两个事件$A$和$B$，有：
   $$
   P(A \cap B) = P(A|B) \cdot P(B)
   $$
   或
   $$
   P(A \cap B) = P(B|A) \cdot P(A)
   $$

2. **推广形式**：
   对于$n$个事件$A_1, A_2, \dots, A_n$，有：
   $$
   P(A_1 \cap A_2 \cap \dots \cap A_n) = P(A_1) \cdot P(A_2|A_1) \cdot P(A_3|A_1 \cap A_2) \cdots P(A_n|A_1 \cap A_2 \cap \dots \cap A_{n-1})
   $$

乘法公式通过条件概率将多个事件同时发生的概率分解为单个事件的概率及其条件概率的乘积。

### 1.4.3 全概率公式与贝叶斯公式

#### 1.4.3.1 样本空间划分

设 $(\varOmega, \mathcal{F}, P)$ 是一个概率空间，其中$\varOmega$ 是**样本空间**，若一组事件 $\{A_i\}_{i \in I}$ 满足：
1. $A_i \cap A_j = \varnothing \quad (\forall i \neq j)$

2. $\begin{align*}\bigcup_{i=1}^n A_i = \varOmega\end{align*}$

则称 $\{A_i\}$ 为 $\Omega$ 的一个**划分**（partition）。

当 $I$ 是有限指标集时，这样的划分 $\{A_i\}$ 称为**完备事件组**；当 $I$ 是可数无穷指标集时，称为**可列无穷划分**。在完备事件组中，事件 $A_i$ 之间两两互斥且它们的并集等于样本空间。

**性质：**

1. **互斥性**：$A_i$ 之间两两不交（$P(A_i \cap A_j) = 0$ 当 $i \neq j$）

2. **完备性**：所有 $A_i$ 的并覆盖样本空间（$P\left(\bigcup_i A_i\right) = 1$）

#### 1.4.3.2 全概率公式

**全概率公式**是概率论中用于计算一个事件的总概率的重要工具，特别是当该事件的发生依赖于多个互斥且完备的事件时。

设$B_1, B_2, \dots, B_n$是一组样本空间的划分，则对于任意事件$A$，其概率可以表示为：

$$
P(A) = \sum_{i=1}^n P(A|B_i) \cdot P(B_i)
$$

#### 1.4.3.3 贝叶斯公式

**贝叶斯公式**是概率论中用于更新事件概率的重要工具，特别是在已知某些条件下，重新评估事件发生的概率。它是条件概率和全概率公式的结合。

设$B_1, B_2, \dots, B_n$是一组样本空间的划分，对于任意事件$A$，且$P(A) > 0$，贝叶斯公式定义为：

$$
P(B_i|A) = \frac{P(A|B_i) \cdot P(B_i)}{P(A)}
$$

其中：

- $P(B_i|A)$ 是在事件$A$发生的条件下，事件$B_i$发生的**后验概率**。
- $P(A|B_i)$ 是在事件$B_i$发生的条件下，事件$A$发生的**条件概率**。
- $P(B_i)$ 是事件$B_i$发生的**先验概率**。
- $P(A)$ 是事件$A$发生的总概率，可以通过**全概率公式**计算：

$$
P(A) = \sum_{i=1}^n P(A|B_i) \cdot P(B_i)
$$

贝叶斯公式的核心思想是利用已知的信息（$A$发生）来更新我们对事件$B_i$发生概率的估计。它从先验概率$P(B_i)$出发，结合条件概率$P(A|B_i)$，得到后验概率$P(B_i|A)$。

## 1.5 随机事件的独立性

随机事件的独立性是概率论中的核心概念之一，它描述了事件之间没有相互影响或关联的特性。直观上，如果一个事件的发生与否不会改变另一个事件发生的概率，则称这两个事件是独立的。独立性概念在概率论和统计学中具有重要地位，它不仅简化了概率计算，也是构建许多概率模型的基础。

### 1.5.1 两个事件的独立性

设$A$和$B$是两个事件，若满足以下条件之一，则称$A$和$B$**相互独立**：

1. $P(A \cap B) = P(A) \cdot P(B)$。
2. $P(A|B) = P(A)$（当$P(B) > 0$时）。
3. $P(B|A) = P(B)$（当$P(A) > 0$时）。

事件$A$和$B$的独立性意味着事件$A$的发生与否不影响事件$B$的发生概率，反之亦然。

**性质**：

1. 若$A$和$B$独立，则$A$和$\overline{B}$、$\overline{A}$和$B$、$\overline{A}$和$\overline{B}$也独立。这四个命题间两两互为充要条件。

2. 独立性与互斥性不同：互斥事件$A$和$B$满足$P(A \cap B) = 0$，而独立事件$A$和$B$满足$P(A \cap B) = P(A) \cdot P(B)$，两者不能同时成立（除非$P(A) = 0$或$P(B) = 0$）。

**直观理解**：

独立性可以通过以下方式来理解：
- 如果已知事件$B$已经发生，事件$A$发生的概率仍然是$P(A)$，那么$A$和$B$是独立的。
- 当抛两枚硬币时，第一枚硬币的结果不会影响第二枚硬币的结果，因此这两个事件是独立的。
- 独立性表示事件之间没有任何"因果关系"或"信息联系"。

**与条件概率的关系**：

独立性与条件概率密切相关。当$A$和$B$独立时：
- 条件概率$P(A|B) = P(A)$，表示已知$B$发生的情况下，$A$发生的概率与$B$是否发生无关。
- 这也意味着$P(B|A) = P(B)$，即已知$A$发生的情况下，$B$发生的概率与$A$是否发生无关。
- 从乘法公式看，当$A$和$B$独立时，$P(A \cap B) = P(A) \cdot P(B)$，计算交事件概率变得简单。

**互斥与独立的区别**：

独立性和互斥性是两个本质不同的概念：

- **互斥性**：如果两个事件不能同时发生，即$P(A \cap B) = 0$，则称它们是互斥的。互斥描述的是事件发生的不兼容性。
  
- **独立性**：如果一个事件的发生不影响另一个事件发生的概率，即$P(A \cap B) = P(A) \cdot P(B)$，则称它们是独立的。独立描述的是事件发生的不相关性。

对于$P(A) > 0$且$P(B) > 0$的事件，互斥和独立是不兼容的。因为：
- 如果$A$和$B$互斥，则$P(A \cap B) = 0$
- 如果$A$和$B$独立，则$P(A \cap B) = P(A) \cdot P(B) > 0$

直观理解：如果两个事件互斥，那么一个事件的发生必然导致另一个事件不发生，它们之间存在明显的影响关系，因此不可能独立。

### 1.5.2 多个事件的独立性

设$A_1, A_2, \dots, A_n$是$n$个事件，若对于任意$k$（$2 \leq k \leq n$）和任意$1 \leq i_1 < i_2 < \dots < i_k \leq n$，都有：
$$
P(A_{i_1} \cap A_{i_2} \cap \dots \cap A_{i_k}) = P(A_{i_1}) \cdot P(A_{i_2}) \cdots P(A_{i_k})
$$
则称$A_1, A_2, \dots, A_n$**相互独立**。

多个事件的独立性意味着任意子集的事件同时发生的概率等于各事件概率的乘积。

**性质**：

1. 若$A_1, A_2, \dots, A_n$相互独立，则其中任意部分事件也相互独立。
2. 若$A_1, A_2, \dots, A_n$相互独立，则对任意事件$A_i$取补集后，事件组仍然相互独立。

**重要概念**：

1. **两两独立与相互独立的区别**：
   - 事件组$A_1, A_2, \dots, A_n$两两独立是指对任意$i \neq j$，事件$A_i$和$A_j$独立。
   - 而相互独立要求任意$k$个事件的交事件概率等于各事件概率的乘积。
   - 两两独立不一定推出相互独立，但相互独立可以推出两两独立。

2. **条件独立性**：

   若在给定事件$C$的条件下，对任意事件$A$和$B$，满足$P(A \cap B | C) = P(A|C) \cdot P(B|C)$，则称$A$和$B$在条件$C$下条件独立。条件独立性在贝叶斯网络等概率模型中有重要应用。

**独立性的应用**：

1. **简化概率计算**：

   当多个事件相互独立时，它们的交事件概率等于各事件概率的乘积，这大大简化了复杂情况下的概率计算。

2. **独立重复试验**：

   伯努利试验是典型的独立重复试验。例如，独立地抛掷硬币n次，得到正面的概率为p，则得到k次正面的概率可以用二项分布来描述：$P(X = k) = C_n^k p^k (1-p)^{n-k}$。